{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Graph Classification: Protein Dataset\n",
    "- Goal: Classify each protein as an enzyme, a binary classification task\n",
    "- This dataset does not contain any edge features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: PROTEINS(1113)\n",
      "-----------------------\n",
      "Number of graphs: 1113\n",
      "Number of nodes: 7\n",
      "Number of features: 3\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root='./data', name='PROTEINS').shuffle()\n",
    "\n",
    "print(f'Dataset: {dataset}')\n",
    "print('-----------------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {dataset[0].x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T14:23:54.565450846Z",
     "start_time": "2023-07-02T14:23:51.070318914Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set = 890 graphs\n",
      "Validation set = 111 graphs\n",
      "Test set = 112 graphs\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_dataset = dataset[: int(len(dataset) * 0.8)]\n",
    "val_dataset = dataset[int(len(dataset) * 0.8): int(len(dataset) * 0.9)]\n",
    "test_dataset = dataset[int(len(dataset) * 0.9):]\n",
    "\n",
    "print(f'Training set = {len(train_dataset)} graphs')\n",
    "print(f'Validation set = {len(val_dataset)} graphs')\n",
    "print(f'Test set = {len(test_dataset)} graphs')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T14:23:54.587704133Z",
     "start_time": "2023-07-02T14:23:54.567566700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mini-batch: 64 graphs\n",
    "- This means each batch will contain up to 64 graphs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loader:\n",
      "- Batch 0: DataBatch(edge_index=[2, 8696], x=[2296, 3], y=[64], batch=[2296], ptr=[65])\n",
      "- Batch 1: DataBatch(edge_index=[2, 10620], x=[2865, 3], y=[64], batch=[2865], ptr=[65])\n",
      "- Batch 2: DataBatch(edge_index=[2, 8684], x=[2367, 3], y=[64], batch=[2367], ptr=[65])\n",
      "- Batch 3: DataBatch(edge_index=[2, 9616], x=[2683, 3], y=[64], batch=[2683], ptr=[65])\n",
      "- Batch 4: DataBatch(edge_index=[2, 8904], x=[2414, 3], y=[64], batch=[2414], ptr=[65])\n",
      "- Batch 5: DataBatch(edge_index=[2, 13002], x=[3430, 3], y=[64], batch=[3430], ptr=[65])\n",
      "- Batch 6: DataBatch(edge_index=[2, 9802], x=[2638, 3], y=[64], batch=[2638], ptr=[65])\n",
      "- Batch 7: DataBatch(edge_index=[2, 8616], x=[2282, 3], y=[64], batch=[2282], ptr=[65])\n",
      "- Batch 8: DataBatch(edge_index=[2, 9552], x=[2551, 3], y=[64], batch=[2551], ptr=[65])\n",
      "- Batch 9: DataBatch(edge_index=[2, 9106], x=[2412, 3], y=[64], batch=[2412], ptr=[65])\n",
      "- Batch 10: DataBatch(edge_index=[2, 9168], x=[2431, 3], y=[64], batch=[2431], ptr=[65])\n",
      "- Batch 11: DataBatch(edge_index=[2, 10590], x=[2764, 3], y=[64], batch=[2764], ptr=[65])\n",
      "- Batch 12: DataBatch(edge_index=[2, 7316], x=[2015, 3], y=[64], batch=[2015], ptr=[65])\n",
      "- Batch 13: DataBatch(edge_index=[2, 8492], x=[2278, 3], y=[58], batch=[2278], ptr=[59])\n",
      "\n",
      "Validation loader:\n",
      "- Batch 0: DataBatch(edge_index=[2, 8612], x=[2304, 3], y=[64], batch=[2304], ptr=[65])\n",
      "- Batch 1: DataBatch(edge_index=[2, 5172], x=[1422, 3], y=[47], batch=[1422], ptr=[48])\n",
      "\n",
      "Test loader:\n",
      " - Batch 0: DataBatch(edge_index=[2, 8602], x=[2283, 3], y=[64], batch=[2283], ptr=[65])\n",
      " - Batch 1: DataBatch(edge_index=[2, 7538], x=[2036, 3], y=[48], batch=[2036], ptr=[49])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "print('\\nTrain loader:')\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f'- Batch {i}: {batch}')\n",
    "\n",
    "print('\\nValidation loader:')\n",
    "for i, batch in enumerate(val_loader):\n",
    "    print(f'- Batch {i}: {batch}')\n",
    "\n",
    "print('\\nTest loader:')\n",
    "for i, batch in enumerate(test_loader):\n",
    "    print(f' - Batch {i}: {batch}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T14:23:54.746694496Z",
     "start_time": "2023-07-02T14:23:54.577521596Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Layer Composition\n",
    "- Linear -> BatchNorm -> ReLU -> Linear -> ReLU"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "from torch_geometric.nn import GINConv\n",
    "from torch_geometric.nn import global_add_pool\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, dim_h):\n",
    "        super(GIN, self).__init__()\n",
    "\n",
    "        # GIN layers\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(dataset.num_node_features, dim_h),\n",
    "                       BatchNorm1d(dim_h),\n",
    "                       ReLU(),\n",
    "                       Linear(dim_h, dim_h),\n",
    "                       ReLU())\n",
    "        )\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h),\n",
    "                       BatchNorm1d(dim_h),\n",
    "                       ReLU(),\n",
    "                       Linear(dim_h, dim_h),\n",
    "                       ReLU())\n",
    "        )\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h),\n",
    "                       BatchNorm1d(dim_h),\n",
    "                       ReLU(),\n",
    "                       Linear(dim_h, dim_h),\n",
    "                       ReLU())\n",
    "        )\n",
    "\n",
    "        # Graph-level pooling layer /readout layer\n",
    "        # Here we add each layer as recommended in GIN papaer\n",
    "        self.lin1 = Linear(dim_h * 3, dim_h * 3)\n",
    "\n",
    "        # Final Classification head\n",
    "        self.lin2 = Linear(dim_h * 3, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Node embedding\n",
    "        h1 = self.conv1(x, edge_index)\n",
    "        h2 = self.conv2(h1, edge_index)\n",
    "        h3 = self.conv3(h2, edge_index)\n",
    "\n",
    "        # Graph-level readout\n",
    "        h1 = global_add_pool(h1, batch)\n",
    "        h2 = global_add_pool(h2, batch)\n",
    "        h3 = global_add_pool(h3, batch)\n",
    "\n",
    "        # Concatenate graph embeddings\n",
    "        h = torch.cat((h1, h2, h3), dim=1)\n",
    "\n",
    "        # Classifier\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        # print(h.shape)\n",
    "\n",
    "        return F.log_softmax(h, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T14:23:55.048609206Z",
     "start_time": "2023-07-02T14:23:54.746053097Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Test functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def accuracy(pred_y, y):\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "def train(model, loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    epochs = 100\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs + 1):\n",
    "        total_loss = 0\n",
    "        acc = 0\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "\n",
    "        # Train on batches\n",
    "        for data in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss / len(loader)\n",
    "            acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Valiadation\n",
    "            val_loss, val_acc = test(model, val_loader)\n",
    "        # Print metrics every 20 epochs\n",
    "        if (epoch % 20 == 0):\n",
    "            print(f'Epoch {epoch:>3} \\\n",
    "                  | Train Loss: {total_loss:.2f} \\\n",
    "                  | Train Acc: {acc*100:>5.2f}% \\\n",
    "                  | ValLoss: {val_loss:.2f}  \\\n",
    "                  | Val Acc: {val_acc*100:.2f}%')\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "\n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss += criterion(out, data.y) / len(loader)\n",
    "        acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n",
    "\n",
    "    return loss, acc\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T14:23:55.064092908Z",
     "start_time": "2023-07-02T14:23:55.052486771Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model with dim_h = 32"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "GIN(\n  (conv1): GINConv(nn=Sequential(\n    (0): Linear(in_features=3, out_features=32, bias=True)\n    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Linear(in_features=32, out_features=32, bias=True)\n    (4): ReLU()\n  ))\n  (conv2): GINConv(nn=Sequential(\n    (0): Linear(in_features=32, out_features=32, bias=True)\n    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Linear(in_features=32, out_features=32, bias=True)\n    (4): ReLU()\n  ))\n  (conv3): GINConv(nn=Sequential(\n    (0): Linear(in_features=32, out_features=32, bias=True)\n    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Linear(in_features=32, out_features=32, bias=True)\n    (4): ReLU()\n  ))\n  (lin1): Linear(in_features=96, out_features=96, bias=True)\n  (lin2): Linear(in_features=96, out_features=2, bias=True)\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gin = GIN(dim_h=32)\n",
    "gin"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T14:23:55.111743499Z",
     "start_time": "2023-07-02T14:23:55.067250025Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's train the model!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0                   | Train Loss: 0.70                   | Train Acc: 63.19%                   | ValLoss: 0.60                    | Val Acc: 71.04%\n",
      "Epoch  20                   | Train Loss: 0.67                   | Train Acc: 63.94%                   | ValLoss: 0.60                    | Val Acc: 70.48%\n",
      "Epoch  40                   | Train Loss: 0.67                   | Train Acc: 63.83%                   | ValLoss: 0.59                    | Val Acc: 71.61%\n",
      "Epoch  60                   | Train Loss: 0.67                   | Train Acc: 63.79%                   | ValLoss: 0.58                    | Val Acc: 72.17%\n",
      "Epoch  80                   | Train Loss: 0.67                   | Train Acc: 63.75%                   | ValLoss: 0.60                    | Val Acc: 71.61%\n",
      "Epoch 100                   | Train Loss: 0.67                   | Train Acc: 63.88%                   | ValLoss: 0.58                    | Val Acc: 71.61%\n"
     ]
    }
   ],
   "source": [
    "gin = train(gin, train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T14:24:40.310960198Z",
     "start_time": "2023-07-02T14:23:55.092239229Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.69 | Test Acc: 62.76%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = test(gin, test_loader)\n",
    "print(f'Test Loss: {test_loss:.2f} | Test Acc: {test_acc * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T14:32:17.548249793Z",
     "start_time": "2023-07-02T14:32:17.508485491Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can compare this test score with other GCNs under sampe setting with a simple global mean pooling as the readout layer. With the exact same setting, GIN often time outperfroms other architectures..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "test_model = GIN(dim_h=32)\n",
    "for data in train_loader:\n",
    "    out = test_model(data.x, data.edge_index, data.batch)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T14:24:40.366387943Z",
     "start_time": "2023-07-02T14:24:40.315763513Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2])\n",
      "tensor([[-3.5728e+01,  0.0000e+00],\n",
      "        [-1.5860e-01, -1.9196e+00],\n",
      "        [-1.4764e+00, -2.5937e-01],\n",
      "        [-7.8700e-03, -4.8486e+00],\n",
      "        [-2.5429e-01, -1.4937e+00],\n",
      "        [-1.2229e-02, -4.4101e+00],\n",
      "        [-1.2679e-01, -2.1279e+00],\n",
      "        [-5.5607e-01, -8.5204e-01],\n",
      "        [-1.0544e+00, -4.2834e-01],\n",
      "        [-5.3672e-02, -2.9516e+00],\n",
      "        [-2.9955e+00, -5.1305e-02],\n",
      "        [-4.7635e-01, -9.7035e-01],\n",
      "        [-8.8076e-02, -2.4733e+00],\n",
      "        [-7.3471e+00, -6.4471e-04],\n",
      "        [-4.8479e-01, -9.5666e-01],\n",
      "        [-2.6226e+00, -7.5381e-02],\n",
      "        [-2.1891e-01, -1.6266e+00],\n",
      "        [-2.0827e+00, -1.3306e-01],\n",
      "        [-2.6529e+00, -7.3051e-02],\n",
      "        [ 0.0000e+00, -2.1647e+01],\n",
      "        [-3.0270e+00, -4.9672e-02],\n",
      "        [-2.7262e+00, -6.7707e-02],\n",
      "        [-8.3078e+00, -2.4661e-04],\n",
      "        [-5.1529e-03, -5.2708e+00],\n",
      "        [-1.0409e+00, -4.3564e-01],\n",
      "        [-1.3642e+00, -2.9515e-01],\n",
      "        [-5.5046e-01, -8.5964e-01],\n",
      "        [-1.0373e+00, -4.3761e-01],\n",
      "        [-6.6726e-01, -7.1972e-01],\n",
      "        [-5.0446e+00, -6.4649e-03],\n",
      "        [-6.6574e-01, -7.2132e-01],\n",
      "        [-1.0276e+00, -4.4296e-01],\n",
      "        [-1.1000e+00, -4.0479e-01],\n",
      "        [-4.1390e+00, -1.6067e-02],\n",
      "        [-7.0811e-01, -6.7841e-01],\n",
      "        [-3.3349e-04, -8.0061e+00],\n",
      "        [-2.5452e+00, -8.1708e-02],\n",
      "        [-1.2435e+00, -3.4020e-01],\n",
      "        [-3.3581e+00, -3.5423e-02],\n",
      "        [-9.4343e-01, -4.9313e-01],\n",
      "        [-5.0842e-03, -5.2842e+00],\n",
      "        [-1.0212e+00, -4.4655e-01],\n",
      "        [-1.9879e+00, -1.4733e-01],\n",
      "        [-1.7229e+00, -1.9668e-01],\n",
      "        [-5.6640e+00, -3.4745e-03],\n",
      "        [-6.1783e-03, -5.0898e+00],\n",
      "        [-1.3800e+00, -2.8980e-01],\n",
      "        [-2.4903e-03, -5.9966e+00],\n",
      "        [-1.0344e+00, -4.3920e-01],\n",
      "        [-7.0344e+01,  0.0000e+00],\n",
      "        [-1.4415e+00, -2.6992e-01],\n",
      "        [-6.3953e-01, -7.4981e-01],\n",
      "        [-8.3783e-01, -5.6678e-01],\n",
      "        [-7.0748e-02, -2.6838e+00],\n",
      "        [-3.0582e+00, -4.8110e-02],\n",
      "        [-4.5841e+00, -1.0265e-02],\n",
      "        [-8.4873e-05, -9.3740e+00],\n",
      "        [-2.2578e+00, -1.1046e-01],\n",
      "        [-4.6996e-01, -9.8090e-01],\n",
      "        [-4.4433e-01, -1.0251e+00],\n",
      "        [-6.8463e+00, -1.0640e-03],\n",
      "        [-1.9889e-01, -1.7128e+00],\n",
      "        [-1.5158e+00, -2.4799e-01],\n",
      "        [-6.9123e+00, -9.9597e-04]], grad_fn=<LogSoftmaxBackward0>)\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(out)\n",
    "print(out.argmax(dim=1).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-02T14:27:28.085872573Z",
     "start_time": "2023-07-02T14:27:28.046652352Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
