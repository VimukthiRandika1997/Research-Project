{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28762856-c849-4d08-95f6-85c76e15cda0",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "89b5df85-42f8-4e86-8efd-0cae1f99cc4e",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576941c0-bb20-4d74-a0e3-7f50967b0484",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "1b635303-29ed-4998-a5bb-583c7c3f3a2b",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch.nn.init import xavier_uniform_, zeros_\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops, degree, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00640a7-1457-411c-a5e8-bae324918c2b",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "0bda0e28-b479-4c2b-9e2d-576468c8437e",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features\n",
      " tensor([[0.1339, 0.6032, 0.3207, 0.7724, 0.3698],\n",
      "        [0.7954, 0.7916, 0.1310, 0.0559, 0.8457],\n",
      "        [0.5854, 0.0704, 0.9769, 0.9597, 0.7408],\n",
      "        [0.7319, 0.3205, 0.5486, 0.9603, 0.5263]]) torch.Size([4, 5])\n",
      "\n",
      "edge_index\n",
      " tensor([[0, 0, 0, 1, 1, 2, 3, 3],\n",
      "        [1, 2, 3, 3, 0, 0, 0, 2]]) torch.Size([2, 8])\n",
      "\n",
      "Edge features\n",
      " tensor([[0.2021, 0.4291, 0.1266, 0.4451, 0.1104],\n",
      "        [0.3644, 0.1243, 0.6007, 0.1617, 0.0896],\n",
      "        [0.8721, 0.3000, 0.7694, 0.2707, 0.6138],\n",
      "        [0.8695, 0.2297, 0.7972, 0.4406, 0.9780],\n",
      "        [0.7250, 0.0640, 0.8526, 0.1394, 0.9993],\n",
      "        [0.4752, 0.5227, 0.4312, 0.0431, 0.8705],\n",
      "        [0.5375, 0.9636, 0.4342, 0.2797, 0.7332],\n",
      "        [0.3975, 0.5066, 0.2974, 0.2837, 0.9275]]) torch.Size([8, 5])\n"
     ]
    }
   ],
   "source": [
    "num_nodes = 4 # number of nodes in the graph\n",
    "embed_size = 5 # initial node features\n",
    "\n",
    "# Creating node features\n",
    "node_feat = torch.rand((num_nodes, embed_size), dtype=torch.float)\n",
    "x = node_feat\n",
    "print('Node features\\n', node_feat, node_feat.shape)\n",
    "\n",
    "# Creating COO format edge_indexes for the graph\n",
    "src_index = torch.tensor([0,0,0,1,1,2,3,3], dtype=torch.long)\n",
    "target_index = torch.tensor([1,2,3,3,0,0,0,2], dtype=torch.long)\n",
    "edge_index = torch.zeros(size=(2, src_index.size()[0]), dtype=torch.int64)\n",
    "edge_index[0] = src_index\n",
    "edge_index[1] = target_index\n",
    "print('\\nedge_index\\n', edge_index, edge_index.shape)\n",
    "\n",
    "# Creating edge features\n",
    "x_edge = torch.rand((edge_index.shape[1], 5), dtype=torch.float) # (num_edges, embed_size)\n",
    "print('\\nEdge features\\n', x_edge, x_edge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95de5483-07f3-49b2-a741-b05b0c9b2780",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "4d898dcf-bf8d-4d44-886e-c47facf708ee",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr='add') # aggregation \n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # add self loops\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        # initial feature transform\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "    \n",
    "    def message(self, x_j, edge_index, size):\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        \n",
    "        # print(norm.view(-1, 1))\n",
    "        return norm.view(-1, 1) * x_j\n",
    "    \n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6adf023-8da5-46af-8fc8-b660a059a48d",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "22d731be-a6d8-4367-8d36-528dfef372c2",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass\n",
      "\n",
      "res\n",
      " tensor([[-0.2242, -0.3125,  0.8685, -0.8613, -0.2454,  0.3702, -0.8251,  0.1788,\n",
      "         -0.0387, -0.1061,  0.2458,  0.0949],\n",
      "        [-0.1680, -0.0349,  0.3368, -0.3738, -0.0404,  0.1945, -0.3948,  0.1143,\n",
      "         -0.1057,  0.0622,  0.1184,  0.0454],\n",
      "        [-0.1638, -0.4710,  1.0498, -0.9654, -0.3504,  0.4334, -0.8794,  0.0887,\n",
      "          0.1200, -0.1498,  0.2659,  0.1456],\n",
      "        [-0.2308, -0.1513,  0.6065, -0.6451, -0.1382,  0.3111, -0.6684,  0.1496,\n",
      "         -0.1025, -0.0131,  0.2315,  0.0826]], grad_fn=<ScatterAddBackward0>) torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "gcn = GCNConv(embed_size, 12)\n",
    "print('Forward pass')\n",
    "res = gcn.forward(x, edge_index)\n",
    "print('\\nres\\n', res, res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01efa2bf-d8fb-44b3-b41c-1d16d488188c",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "941ec1c0-81fc-40c8-8d89-ef571b083cd3",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "# GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c85a17ae-cc5e-4532-929e-4b930c3b78ec",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "0c40d19c-ed6a-4f77-b372-69823a643c8c",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "class GraphSAGE(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, reducer='mean', normalize_embedding=True):\n",
    "        super(GraphSAGE, self).__init__(aggr='mean') # Aggregate\n",
    "        self.aggr_lin = torch.nn.Linear(in_channels * 2, out_channels)\n",
    "        \n",
    "        if normalize_embedding:\n",
    "            self.normalize = True\n",
    "            \n",
    "    def forward(self, x, edge_index):\n",
    "        num_nodes = x.size(0)\n",
    "        \n",
    "        return self.propagate(edge_index, size=(num_nodes, num_nodes), x=x)\n",
    "    \n",
    "    def message(self, x_j, edge_index, size):\n",
    "        return x_j\n",
    "    \n",
    "    def update(self, aggr_out):\n",
    "        # Concate and transform\n",
    "        concat_out = torch.cat((x, aggr_out), dim=1)\n",
    "        aggr_out = self.aggr_lin(concat_out)\n",
    "        aggr_out = F.relu(aggr_out)\n",
    "        \n",
    "        if self.normalize:\n",
    "            aggr_out = F.normalize(aggr_out, p=2, dim=1)\n",
    "        # print(aggr_out.shape)\n",
    "       \n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62bd5052-c7ff-4555-84de-a39010d93fbf",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "07044928-d663-44ea-bd1d-1a1d92b994b7",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "res\n",
      " tensor([[0.1311, 0.2816, 0.2891, 0.2310, 0.8252, 0.0000, 0.0000, 0.1016, 0.1328,\n",
      "         0.0000, 0.2400, 0.0000],\n",
      "        [0.2585, 0.0000, 0.0000, 0.2647, 0.8878, 0.0000, 0.0000, 0.2189, 0.0619,\n",
      "         0.1523, 0.0000, 0.0000],\n",
      "        [0.1815, 0.3459, 0.2146, 0.2531, 0.6026, 0.0000, 0.0000, 0.4979, 0.2567,\n",
      "         0.0000, 0.2456, 0.0000],\n",
      "        [0.1105, 0.0880, 0.2681, 0.3348, 0.7681, 0.0000, 0.0000, 0.4339, 0.0354,\n",
      "         0.0000, 0.1284, 0.0000]], grad_fn=<DivBackward0>) torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "graphsage = GraphSAGE(embed_size, 12)\n",
    "res = graphsage.forward(x, edge_index)\n",
    "print('\\nres\\n', res, res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df567d0d-d8ea-44d6-91bd-080819cec67c",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "5fe7a8d9-0991-475e-b10a-3bff3588b843",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "# GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ad1cce-66e8-4cf9-9878-abad0d058d9e",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "7b64f2e5-26e9-4658-919e-f2ce58b310ed",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "class GAT(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, num_heads=1, concat=True ,dropout=0, bias=True, **kwargs):\n",
    "        super(GAT, self).__init__(aggr='add', **kwargs)\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = int(out_channels / num_heads) # out_channels must be multiplication of num_heads\n",
    "        self.heads = num_heads\n",
    "        self.concat = concat\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.lin = Linear(self.in_channels, self.out_channels * num_heads) # Linear transformation\n",
    "        self.att = Parameter(torch.Tensor(1, self.heads, self.out_channels * 2)) # Learnable attention matrix\n",
    "        \n",
    "        if bias and concat:\n",
    "            self.bias = Parameter(torch.Tensor(self.heads * self.out_channels))\n",
    "        elif bias and not concat:\n",
    "            self.bias = Parameter(torch.Tensor(self.out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        xavier_uniform_(self.att)\n",
    "        zeros_(self.bias)\n",
    "    \n",
    "    \n",
    "    def forward(self, x, edge_index, size=None):\n",
    "        # Adding self-loops for the graph...\n",
    "        if size is None and torch.is_tensor(x):\n",
    "            edge_index, _ = remove_self_loops(edge_index)\n",
    "            edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        \n",
    "        x = self.lin(x) # linear transformation\n",
    "        \n",
    "        return self.propagate(edge_index, size=size, x=x)\n",
    "    \n",
    "    def message(self, edge_index_i, x_i, x_j, size_i):\n",
    "        # Compute attention coefficient\n",
    "        x_i = x_i.view(-1, self.heads, self.out_channels) # split hidden features into multi-heads\n",
    "        x_j = x_j.view(-1, self.heads, self.out_channels)\n",
    "        \n",
    "        # Concate source and target node hidden features\n",
    "        # Compute cosine similarity on the last axis: inner product\n",
    "        alpha = (torch.cat([x_i, x_j], dim=-1) * self.att).sum(dim=-1)\n",
    "        alpha = F.leaky_relu(alpha, 0.2)\n",
    "        print(alpha.shape)\n",
    "        print(edge_index_i)\n",
    "        print(size_i)\n",
    "        \n",
    "        # Softmax: will call 'scatter_add' internaly\n",
    "        alpha = softmax(alpha, edge_index_i, num_nodes=size_i)\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        \n",
    "        print(alpha.view(-1, self.heads, 1).shape)\n",
    "        print(x_j.shape)\n",
    "        print('tmp', (x_j * torch.unsqueeze(alpha, dim=-1)).shape)\n",
    "        \n",
    "        # return x_j * alpha.view(-1, self.heads, 1) # weighted input: (alpha * src nodes features)\n",
    "        return x_j * torch.unsqueeze(alpha, dim=-1)\n",
    "        \n",
    "    def update(self, aggr_out):\n",
    "        print('aggr', aggr_out.shape)\n",
    "        if self.concat is True:\n",
    "            aggr_out = aggr_out.view(-1, self.heads * self.out_channels)\n",
    "        else:\n",
    "            aggr_out = aggr_out.mean(dim=1) # For the last layer, just aggregation\n",
    "        if self.bias is not None:\n",
    "            aggr_out = aggr_out + self.bias\n",
    "        \n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f2ee6c-10b5-408a-9b1f-398cd68ab314",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "81673c8d-815a-4bd7-94a8-86f8186900a7",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1])\n",
      "tensor([1, 2, 3, 3, 0, 0, 0, 2, 0, 1, 2, 3])\n",
      "4\n",
      "torch.Size([12, 1, 1])\n",
      "torch.Size([12, 1, 100])\n",
      "tmp torch.Size([12, 1, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (12) at non-singleton dimension 1.  Target sizes: [12, 1, 100].  Tensor sizes: [1, 12, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_795247/2376518613.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_795247/1965595489.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# linear transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                         \u001b[0maggr_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msegment_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             return scatter(inputs, index, dim=self.node_dim, dim_size=dim_size,\n\u001b[0m\u001b[1;32m    428\u001b[0m                            reduce=self.aggr)\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, out, dim_size, reduce)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \"\"\"\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sum'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mul'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch_scatter/scatter.py\u001b[0m in \u001b[0;36mscatter_sum\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 dim_size: Optional[int] = None) -> torch.Tensor:\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch_scatter/utils.py\u001b[0m in \u001b[0;36mbroadcast\u001b[0;34m(src, other, dim)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (12) at non-singleton dimension 1.  Target sizes: [12, 1, 100].  Tensor sizes: [1, 12, 1]"
     ]
    }
   ],
   "source": [
    "gat = GAT(embed_size, 100)\n",
    "gat.forward(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "623a4f2f-811f-4f2e-91fd-5030cc52975c",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "36693d76-218a-4761-94b0-0707bda598eb",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100]) torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "gat = GATv2Conv(5, 100)\n",
    "res1, res2 = gat.forward(x, edge_index, return_attention_weights=True)\n",
    "print(res1[0].shape, res2[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d3e83c73-4fb9-4627-a92a-389abc44a9d7",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "b80217af-3a5f-485a-8508-297118b42a10",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "class GAT(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, heads=1, concat=True ,dropout=0, bias=True, **kwargs):\n",
    "        super(GAT, self).__init__(aggr='add', **kwargs)\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels # out_channels must be multiplication of num_heads\n",
    "        self.heads = heads\n",
    "        self.concat = concat\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Linear transformations\n",
    "        self.lin_src = Linear(in_channels, heads * out_channels, bias=False)\n",
    "        self.lin_dst = Linear(in_channels, heads * out_channels, bias=False)\n",
    "        self.lin = Linear(in_channels, heads * out_channels, bias=False)\n",
    "        \n",
    "        # The learnable parameters to compute attention coefficients:\n",
    "        self.att_src = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        self.att_dst = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "\n",
    "        \n",
    "        if bias and concat:\n",
    "            self.bias = Parameter(torch.Tensor(self.heads * self.out_channels))\n",
    "        elif bias and not concat:\n",
    "            self.bias = Parameter(torch.Tensor(self.out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        xavier_uniform_(self.att_src)\n",
    "        xavier_uniform_(self.att_dst)\n",
    "        zeros_(self.bias)\n",
    "    \n",
    "    \n",
    "    def forward(self, x, edge_index, size=None):\n",
    "        # Adding self-loops for the graph...\n",
    "        if size is None and torch.is_tensor(x):\n",
    "            edge_index, _ = remove_self_loops(edge_index)\n",
    "            edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        \n",
    "        H, C = self.heads, self.out_channels\n",
    "        \n",
    "        x_src = torch.index_select(x, 0, edge_index[0]) # selecting source node features\n",
    "        x_dst = torch.index_select(x, 0, edge_index[1]) # selecting target node features\n",
    "        \n",
    "        # Source and Target wise Linear Transformation\n",
    "        x_src = self.lin_src(x_src).view(-1, H, C)\n",
    "        x_dst = self.lin_src(x_dst).view(-1, H, C)\n",
    "        \n",
    "        x = (x_src, x_dst)\n",
    "        # x = self.lin(x).view(-1, H, C)\n",
    "        # print((self.lin(x).view(-1, H, C).shape))\n",
    "        # print(x.shape)\n",
    "        # print(x_src.shape)\n",
    "        # x = torch.cat([x, x], dim=1)\n",
    "        \n",
    "        \n",
    "        # Calcualting attention coefficients\n",
    "        alpha_src = (x_src * self.att_src).sum(dim=-1)\n",
    "        alpha_dst = (x_dst * self.att_dst).sum(dim=-1)\n",
    "        alpha = (alpha_src, alpha_dst)\n",
    "            \n",
    "        alpha = self.edge_updater(edge_index, alpha=alpha)\n",
    "        out = self.propagate(edge_index, x=x, size=size, alpha=alpha)\n",
    "       \n",
    "        if self.concat:\n",
    "            out = out.view(-1, self.heads * self.out_channels)\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "            \n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "        \n",
    "        return out\n",
    "        \n",
    "    def edge_update(self, alpha_j, alpha_i, index, ptr, size_i):\n",
    "        # This will calculate attetntion score for the whole graph...\n",
    "        \n",
    "        alpha = alpha_j if alpha_i is None else alpha_j + alpha_i\n",
    "        if index.numel() == 0:\n",
    "            return alpha\n",
    "        \n",
    "        alpha = F.leaky_relu(alpha, 0.2)\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        return alpha\n",
    "    \n",
    "    def message(self, x_j, alpha):\n",
    "        # return alpha.unsqueeze(-1) * x_j\n",
    "        # print((alpha * x_j).shape)\n",
    "        return x_j * alpha\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a827454b-ab00-4d48-9311-c157df8243e0",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "0594e89b-8230-47f9-bfae-215ed63221dc",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "INDICES element is out of DATA bounds, id=1 axis_dim=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_795247/3920534635.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_795247/3200865383.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_updater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m                         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomp_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                 coll_dict = self.__collect__(self.__user_args__, edge_index,\n\u001b[0m\u001b[1;32m    310\u001b[0m                                              size, kwargs)\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m__collect__\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_size__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__lift__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m__lift__\u001b[0;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: INDICES element is out of DATA bounds, id=1 axis_dim=1"
     ]
    }
   ],
   "source": [
    "gat = GAT(embed_size, 10)\n",
    "gat.forward(x, edge_index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d9e33176-7342-4ae5-944d-eeb06abdee06",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "27d8bcbb-1c4b-4afa-810c-cb5f5c014c8d",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "class GAT(MessagePassing):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, \n",
    "        out_channels,\n",
    "        heads=1,\n",
    "        concat=True,\n",
    "        negative_slope=0.2,\n",
    "        dropout=0.0,\n",
    "        add_self_loops=True,\n",
    "        bias=True,\n",
    "        share_weights=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(node_dim=0, **kwargs)\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.concat = concat\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "        self.add_self_loops = add_self_loops\n",
    "        self.share_weights = share_weights\n",
    "        \n",
    "        self.lin_l = Linear(in_channels, heads * out_channels, bias=bias,)\n",
    "        \n",
    "        if share_weights:\n",
    "            self.lin_r = self.lin_l\n",
    "        else:\n",
    "            self.lin_r = Linear(in_channels, heads * out_channels, bias=bias)\n",
    "            \n",
    "        self.att = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        \n",
    "        if bias and concat:\n",
    "            self.bias = Parameter(torch.Tensor(heads * out_channels))\n",
    "        elif bias and concat:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self._alpha = None\n",
    "\n",
    "        xavier_uniform_(self.att)\n",
    "        zeros_(self.bias)        \n",
    "        \n",
    "    def forward(self, x, edge_index, return_attention_weights=None):\n",
    "        H, C = self.heads, self.out_channels\n",
    "        \n",
    "        x_l = None\n",
    "        x_r = None\n",
    "        \n",
    "        x_l = self.lin_l(x).view(-1, H, C)\n",
    "        if self.share_weights:\n",
    "            x_r = x_l\n",
    "        else:\n",
    "            x_r = self.lin_r(x).view(-1, H, C)\n",
    "            \n",
    "        assert x_l is not None\n",
    "        assert x_r is not None\n",
    "        \n",
    "        if self.add_self_loops:\n",
    "            if torch.is_tensor(edge_index):\n",
    "                num_nodes = x_l.size(0)\n",
    "                if x_r is not None:\n",
    "                    num_nodes = min(num_nodes, x_r.size(0))\n",
    "                edge_index, _ = remove_self_loops(edge_index)\n",
    "                edge_index, _ = add_self_loops(edge_index, num_nodes=num_nodes)\n",
    "                \n",
    "        out = self.propagate(edge_index, x=(x_l, x_r), size=None)\n",
    "        print(out.shape)\n",
    "        \n",
    "        alpha = self._alpha\n",
    "        assert alpha is not None\n",
    "        self._alpha = None\n",
    "        \n",
    "        if self.concat:\n",
    "            out = out.view(-1, self.heads * self.out_channels)\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "            \n",
    "        if isinstance(return_attention_weights, bool):\n",
    "            if torch.is_tensor(edge_index):\n",
    "                return out, (edge_index, alpha)\n",
    "        else:   \n",
    "            return out\n",
    "    \n",
    "    def message(self, x_j, x_i, index, ptr, size_i):\n",
    "        x = x_i + x_j\n",
    "        \n",
    "        x = F.leaky_relu(x, self.negative_slope)\n",
    "        alpha = (x * self.att).sum(dim=-1)\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        self._alpha = alpha\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        \n",
    "        return x_j * alpha.unsqueeze(-1)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0d197fb8-a7c1-4cee-9e4a-14a5d667a794",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "b656e0db-2ff0-4741-a0df-1950ba7ee8c0",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gat = GAT(embed_size, 10)\n",
    "gat.forward(x, edge_index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279880b8-60f1-4911-a1d5-351739917288",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "561c961b-1b6c-4128-992d-8a053c63ef31",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
